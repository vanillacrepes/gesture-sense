---

# ‚úã GestureSense

**GestureSense** is a real-time hand gesture controller that lets you control your computer using just your hands ‚Äî no touchpad or mouse needed. Powered by OpenCV, MediaPipe, and PyAutoGUI, this project transforms your webcam into a gesture-based input system.

---

## üöÄ Features

| Gesture                        | Action               |
| ------------------------------ | -------------------- |
| ‚òùÔ∏è Move index finger           | Control mouse cursor |
| ü§è Pinch or lower index        | Left click & hold    |
| ‚úåÔ∏è Pinch or lower middle       | Right click & hold   |
| üëç Raise thumb                 | Scroll up            |
| üëé Lower thumb                 | Scroll down          |
| ‚úä + üëç Thumb out               | Type "A"             |
| ‚úã All fingers up               | Type "B"             |
| ü§ö Curved fingers left         | Type "C"             |
| üëà Swipe left (with left hand) | Switch control modes |

---

## üéÆ Modes

You can switch between different gesture modes using your **left hand**:

* üñ±Ô∏è **Mouse Mode** ‚Äî Move the cursor, click, and scroll.
* üî§ **Typing Mode** ‚Äî Type basic ASL letters like A, B, and C.
* üß≠ **Radial Mode** ‚Äî Debug or expand with radial gesture detection.

---

## üíª Requirements

* Python 3.7 or later
* A working webcam

### Python Packages

Install dependencies using pip:

```bash
pip install opencv-python mediapipe pyautogui
```

---

## üõ†Ô∏è Installation & Usage

1. Clone the repository:

```bash
git clone https://github.com/your-username/gesture-sense.git
cd gesture-sense
```

2. Run the main script:

```bash
python main.py
```

3. Raise your right hand and start interacting!

---

## ‚öôÔ∏è Configuration

You can tweak the system to your liking by modifying these variables in `main.py`:

```python
pinch_threshold = 0.02  # Pinch detection sensitivity
cursor_smoothing_factor = 0.5  # Cursor movement smoothing
screen_width = 1920
screen_height = 1080
```

---

## üß† How It Works

GestureSense uses:

* **MediaPipe Hands** ‚Äî for fast, real-time hand and finger tracking
* **OpenCV** ‚Äî for capturing and displaying video frames
* **PyAutoGUI** ‚Äî to simulate mouse and keyboard actions

The system detects finger positions and angles, recognizes patterns (like pinches or hand shapes), and maps them to mouse or keyboard input.

---

## üöß Limitations

* ASL typing is limited to basic gestures (A‚ÄìC) and is proof-of-concept.
* Hand tracking accuracy depends on lighting and webcam quality.
* Multi-hand interaction is limited; only one hand controls at a time.

---

## üå± Future Enhancements

* üî† Full ASL alphabet support
* üß© Gesture customization and GUI-based training
* üí° On-screen visual gesture guides
* üñ•Ô∏è Multi-screen support
* üîÑ Two-handed simultaneous gestures

---

## üôå Acknowledgments

* [MediaPipe](https://github.com/google/mediapipe) by Google
* [OpenCV](https://opencv.org/)
* [PyAutoGUI](https://pyautogui.readthedocs.io/en/latest/)

---

## üìÑ License

This project is licensed under the **MIT License**. See the `LICENSE` file for more info.

---

> Built with ‚ù§Ô∏è by a science high schooler passionate about AI and computer vision.

---